{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1e5c40-506e-4855-9f5a-d8f77767877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment'],\n",
       "        num_rows: 31232\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment'],\n",
       "        num_rows: 5205\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment'],\n",
       "        num_rows: 5206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a32790-d976-4ffd-97af-773d68ca8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'label', 'sentiment'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'text', 'label', 'sentiment'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'label', 'sentiment'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Take 100 rows from each split using .select\n",
    "small_train = dataset[\"train\"].select(range(100))\n",
    "small_val   = dataset[\"validation\"].select(range(100))\n",
    "small_test  = dataset[\"test\"].select(range(100))\n",
    "\n",
    "# Build new DatasetDict\n",
    "small_dataset = DatasetDict({\n",
    "    \"train\": small_train,\n",
    "    \"validation\": small_val,\n",
    "    \"test\": small_test\n",
    "})\n",
    "\n",
    "print(small_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158e88c1-e725-4213-b053-fe5677a4367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d319b2-36b0-4d76-861c-b9a6aec4590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████| 100/100 [00:00<00:00, 1876.49 examples/s]\n",
      "Map: 100%|██████████████████████████| 100/100 [00:00<00:00, 15484.56 examples/s]\n",
      "Map: 100%|██████████████████████████| 100/100 [00:00<00:00, 17252.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = small_dataset.map(preprocess, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9786ab22-7ce2-40d2-b2f1-dbbd81a5f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e471d95f-fa06-4b83-8f46-c7b58e8d8528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'labels', 'sentiment', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ac3d8-b0e9-45ee-986a-c9b2c5ffab4c",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dac677f-ef1c-4baf-a211-04b90c9f6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.79kB [00:00, 2.51MB/s]\n",
      "/var/folders/bv/c7b6nvgj05s7ftxp8534dp0w0000gn/T/ipykernel_18421/1538984192.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "\n",
    "from evaluate import load\n",
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)\n",
    "    f1_macro = f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1_macro\": f1_macro[\"f1\"]}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,   # your untrained model\n",
    "    eval_dataset=tokenized_dataset[\"test\"],  # or validation split\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a19e718-a2bd-4683-9d52-37ea6a3b5d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0947623252868652,\n",
       " 'eval_model_preparation_time': 0.0021,\n",
       " 'eval_accuracy': 0.35,\n",
       " 'eval_f1_macro': 0.26352201257861635,\n",
       " 'eval_runtime': 3.289,\n",
       " 'eval_samples_per_second': 30.404,\n",
       " 'eval_steps_per_second': 3.953}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091be0f0-0088-475f-8af7-9d48b573c9a1",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bb237c1-9a60-4645-9523-fd0555affb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bv/c7b6nvgj05s7ftxp8534dp0w0000gn/T/ipykernel_18421/1857627760.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70, training_loss=0.5171008518763951, metrics={'train_runtime': 32.9484, 'train_samples_per_second': 30.35, 'train_steps_per_second': 2.125, 'total_flos': 33117440256000.0, 'train_loss': 0.5171008518763951, 'epoch': 10.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5841951-ede5-4a3b-bba4-838c8ecb1f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9336875677108765,\n",
       " 'eval_accuracy': 0.59,\n",
       " 'eval_f1_macro': 0.5838734090127279,\n",
       " 'eval_runtime': 0.7282,\n",
       " 'eval_samples_per_second': 137.323,\n",
       " 'eval_steps_per_second': 9.613,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "900ed21e-ab21-453f-92f2-64c5c008be07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9807398915290833,\n",
       " 'eval_accuracy': 0.55,\n",
       " 'eval_f1_macro': 0.531547619047619,\n",
       " 'eval_runtime': 0.5768,\n",
       " 'eval_samples_per_second': 173.365,\n",
       " 'eval_steps_per_second': 12.136,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate(tokenized_dataset[\"validation\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b47fa-1c80-4e28-bdea-b44ad297a98a",
   "metadata": {},
   "source": [
    "# After Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42bdbc6e-0b18-47b7-a18b-15b0be5fb40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this movie, it was amazing! -> [[{'label': 'LABEL_0', 'score': 0.0899367555975914}, {'label': 'LABEL_1', 'score': 0.08619707822799683}, {'label': 'LABEL_2', 'score': 0.8238661885261536}]]\n",
      "The film was okay, nothing special. -> [[{'label': 'LABEL_0', 'score': 0.5856354832649231}, {'label': 'LABEL_1', 'score': 0.19563674926757812}, {'label': 'LABEL_2', 'score': 0.21872778236865997}]]\n",
      "This was terrible, I hated it. -> [[{'label': 'LABEL_0', 'score': 0.7305793762207031}, {'label': 'LABEL_1', 'score': 0.12306223064661026}, {'label': 'LABEL_2', 'score': 0.14635835587978363}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True   # get probabilities for all classes\n",
    ")\n",
    "\n",
    "# Example texts\n",
    "examples = [\n",
    "    \"I loved this movie, it was amazing!\",\n",
    "    \"The film was okay, nothing special.\",\n",
    "    \"This was terrible, I hated it.\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    print(text, \"->\", sentiment_pipeline(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816062c1-dedc-4680-9d71-5db0ed82fc0d",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b42331cb-8898-4614-9845-812776577f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_model/tokenizer_config.json',\n",
       " './sentiment_model/special_tokens_map.json',\n",
       " './sentiment_model/vocab.txt',\n",
       " './sentiment_model/added_tokens.json',\n",
       " './sentiment_model/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add label mapping\n",
    "model.config.id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "model.config.label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "# Save model + tokenizer\n",
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56685a58-77c4-495c-ab1c-547ea0cf3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/opt/anaconda3/envs/orpheus_tts/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'negative', 'score': 0.258513480424881}, {'label': 'neutral', 'score': 0.1351109892129898}, {'label': 'positive', 'score': 0.606375515460968}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./sentiment_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_model\")\n",
    "\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "print(sentiment_pipeline(\"The movie was wonderful!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18b20829-3dd3-4f8d-83b0-ca002fb9f14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I really loved this movie, it was amazing!\n",
      "Predicted sentiment: positive (0.82)\n"
     ]
    }
   ],
   "source": [
    "text = \"I really loved this movie, it was amazing!\"\n",
    "\n",
    "outputs = sentiment_pipeline(text, return_all_scores=True)[0]\n",
    "best = max(outputs, key=lambda x: x['score'])\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Predicted sentiment: {best['label']} ({best['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47ee05fc-8814-445a-8970-2fd439aff202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really loved this movie, it was amazing! -> positive (0.82)\n",
      "any plans to go -> neutral (0.41)\n",
      "This was terrible, I hated it. -> negative (0.73)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"I really loved this movie, it was amazing!\",\n",
    "    \"any plans to go\",\n",
    "    \"This was terrible, I hated it.\"\n",
    "]\n",
    "\n",
    "for t in texts:\n",
    "    outputs = sentiment_pipeline(t, return_all_scores=True)[0]\n",
    "    best = max(outputs, key=lambda x: x['score'])\n",
    "    print(f\"{t} -> {best['label']} ({best['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2452fa-db02-473b-a349-e696fbebef68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orpheus TTS",
   "language": "python",
   "name": "orpheus_tts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
